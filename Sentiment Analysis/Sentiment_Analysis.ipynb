{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8bc0ff20",
      "metadata": {
        "id": "8bc0ff20"
      },
      "source": [
        "# 1. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3475abf4",
      "metadata": {
        "id": "3475abf4"
      },
      "outputs": [],
      "source": [
        "pip install --update pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb86246c",
      "metadata": {
        "id": "cb86246c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8756e15e",
      "metadata": {
        "id": "8756e15e"
      },
      "source": [
        "# 2. Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa69b14d",
      "metadata": {
        "id": "aa69b14d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('disaster-train-consolidated.csv')\n",
        "df_val = pd.read_csv('disaster-val-consolidated.csv')\n",
        "df_test = pd.read_csv('disaster-test-consolidated.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a53865",
      "metadata": {
        "id": "d0a53865"
      },
      "source": [
        "# 3. Preprocessing the Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0849cd",
      "metadata": {
        "id": "3b0849cd"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags = re.MULTILINE)\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    new_tokens = [word for word in tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens_stemmed = [stemmer.stem(word) for word in new_tokens]\n",
        "    return \" \".join(tokens_stemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b21eb8",
      "metadata": {
        "id": "35b21eb8"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34cf7337",
      "metadata": {
        "id": "34cf7337"
      },
      "source": [
        "# 4. TF- IDF and Data Assigning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5fe05e4",
      "metadata": {
        "id": "b5fe05e4"
      },
      "outputs": [],
      "source": [
        "tf_idf = TfidfVectorizer()\n",
        "X_train = tf_idf.fit_transform(df['text'])\n",
        "X_val = tf_idf.transform(df_val['text'])\n",
        "X_test = tf_idf.transform(df_test['text'])\n",
        "y_train = df['label']\n",
        "y_val = df_val['label']\n",
        "y_test = df_test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf4775a",
      "metadata": {
        "id": "eaf4775a"
      },
      "outputs": [],
      "source": [
        "train_counts = df['label'].value_counts()\n",
        "val_counts = df_val['label'].value_counts()\n",
        "test_counts = df_test['label'].value_counts()\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
        "axes[0].pie(train_counts, labels=train_counts.index, autopct='%1.1f%%', colors = ['lightblue', 'green'], startangle=180)\n",
        "axes[0].set_title('Training Set Label Distribution')\n",
        "axes[1].pie(val_counts, labels=val_counts.index, autopct='%1.1f%%', colors = ['orange', 'red'] ,startangle=180)\n",
        "axes[1].set_title('Validation Set Label Distribution')\n",
        "axes[2].pie(test_counts, labels=test_counts.index, autopct='%1.1f%%', colors = ['yellow', 'purple'], startangle=180)\n",
        "axes[2].set_title('Test Set Label Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c5e75c",
      "metadata": {
        "id": "50c5e75c"
      },
      "source": [
        "# 5. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266db3a",
      "metadata": {
        "id": "6266db3a"
      },
      "source": [
        "### 5.1 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867022a6",
      "metadata": {
        "id": "867022a6"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2e33e8",
      "metadata": {
        "id": "1f2e33e8"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.3,\n",
        "    'eval_metric': 'logloss',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94120a7f",
      "metadata": {
        "id": "94120a7f"
      },
      "outputs": [],
      "source": [
        "model_eval = [(dtrain, 'train'), (dval, 'val')]\n",
        "bst = xgb.train(parameters, dtrain, num_boost_round=100, evals=model_eval, early_stopping_rounds=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c660c7c",
      "metadata": {
        "id": "3c660c7c"
      },
      "outputs": [],
      "source": [
        "y_predictions = bst.predict(dtest)\n",
        "y_pred = (y_predictions > 0.5).astype(int)\n",
        "print(\"Accuracy Score for XGBoost: \", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-Score: \", f1_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0128b0b8",
      "metadata": {
        "id": "0128b0b8"
      },
      "source": [
        "### 5.2 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dfe097",
      "metadata": {
        "id": "f5dfe097"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f15fa2a",
      "metadata": {
        "id": "5f15fa2a"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(n_estimators = 500, class_weight = 'balanced', random_state = 25)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37fff821",
      "metadata": {
        "id": "37fff821"
      },
      "outputs": [],
      "source": [
        "y_pred = rfc.predict(X_test)\n",
        "print(\"Accuracy of Random Forest: \", accuracy_score(y_test, y_pred))\n",
        "print(\"F1_score: \", f1_score(y_test, y_pred))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f550ee06",
      "metadata": {
        "id": "f550ee06"
      },
      "source": [
        "# 5.3 Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4299f999",
      "metadata": {
        "id": "4299f999"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d341efe5",
      "metadata": {
        "id": "d341efe5"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "word_index = tokenizer.word_index\n",
        "vocabulary_size = len(word_index)\n",
        "print(f\"Vocabulary size: {vocabulary_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69de7916",
      "metadata": {
        "id": "69de7916"
      },
      "outputs": [],
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(df['text'])\n",
        "X_val_seq = tokenizer.texts_to_sequences(df_val['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(df_test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3d3f14",
      "metadata": {
        "id": "2a3d3f14"
      },
      "outputs": [],
      "source": [
        "X_train_padded = pad_sequences(X_train_seq, padding = 'post')\n",
        "X_val_padded = pad_sequences(X_val_seq, padding = 'post')\n",
        "X_test_padded = pad_sequences(X_test_seq, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c5691b",
      "metadata": {
        "id": "31c5691b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6998754",
      "metadata": {
        "id": "f6998754"
      },
      "outputs": [],
      "source": [
        "sequence_lengths_train = [len(sequence) for sequence in X_train_seq]\n",
        "sequence_lengths_val = [len(sequence) for sequence in X_val_seq]\n",
        "sequence_lengths_test = [len(sequence) for sequence in X_test_seq]\n",
        "all_sequence_lengths = sequence_lengths_train + sequence_lengths_val + sequence_lengths_test\n",
        "plt.hist(all_sequence_lengths)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aadf8bb",
      "metadata": {
        "id": "4aadf8bb"
      },
      "outputs": [],
      "source": [
        "percentile = np.percentile(all_sequence_lengths, 95)\n",
        "print(\"95th percentile of sequence length: \", percentile)\n",
        "maxlen = int(percentile)\n",
        "X_train_padded = pad_sequences(X_train_seq, padding='post', maxlen=maxlen)\n",
        "X_val_padded = pad_sequences(X_val_seq, padding='post', maxlen=maxlen)\n",
        "X_test_padded = pad_sequences(X_test_seq, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a4c8c7",
      "metadata": {
        "id": "34a4c8c7"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 120, input_length = maxlen))\n",
        "model.add(Conv1D(128, 5, activation = 'relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(20, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d414e0",
      "metadata": {
        "id": "d6d414e0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29bfadfb",
      "metadata": {
        "id": "29bfadfb"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc712bb",
      "metadata": {
        "id": "4dc712bb"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_padded, y_train, epochs = 20, validation_data = (X_val_padded, y_val), batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ca72c0",
      "metadata": {
        "id": "15ca72c0"
      },
      "outputs": [],
      "source": [
        "y_predictions = (model.predict(X_test_padded) > 0.5).astype('int32')\n",
        "print(\"F1 Score for CNN 1D: \", f1_score(y_test, y_predictions))\n",
        "test_loss, test_acc = model.evaluate(X_test_padded, y_test)\n",
        "print(\"Test Loss: \", test_loss)\n",
        "print(\"Test Accuracy: \", test_acc)\n",
        "print(classification_report(y_test, y_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f49f0d8",
      "metadata": {
        "id": "5f49f0d8"
      },
      "outputs": [],
      "source": [
        "model.save(\"1dcnndisaster.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a993f896",
      "metadata": {
        "id": "a993f896"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "new_model = keras.models.load_model(\"1dcnndisaster.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952e7513",
      "metadata": {
        "id": "952e7513"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "preprocessed_text = preprocess_text(\"How much money would you ride out Hurricane Irma for? Umm no.\")\n",
        "sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
        "padded_sequence = pad_sequences(sequence, maxlen=maxlen)\n",
        "new_model = keras.models.load_model(\"1dcnndisaster.keras\")\n",
        "prediction = new_model.predict(padded_sequence)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd83108f",
      "metadata": {
        "id": "dd83108f"
      },
      "source": [
        "### 5.4 Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c00de12b",
      "metadata": {
        "id": "c00de12b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68216b3d",
      "metadata": {
        "id": "68216b3d"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 120, input_length = maxlen))\n",
        "model.add(SimpleRNN(units = 64, return_sequences = False))\n",
        "model.add(Dense(20, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87058cb2",
      "metadata": {
        "id": "87058cb2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b31116",
      "metadata": {
        "id": "72b31116"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43370eb",
      "metadata": {
        "id": "e43370eb"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_padded, y_train, epochs = 20, validation_data = (X_val_padded, y_val), batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b9ce6a",
      "metadata": {
        "id": "02b9ce6a"
      },
      "outputs": [],
      "source": [
        "y_predictions = (model.predict(X_test_padded) > 0.5).astype('int32')\n",
        "print(\"F1 Score for RNN: \", f1_score(y_test, y_predictions))\n",
        "test_loss, test_acc = model.evaluate(X_test_padded, y_test)\n",
        "print(\"Test Loss: \", test_loss)\n",
        "print(\"Test Accuracy: \", test_acc)\n",
        "print(classification_report(y_test, y_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281b4792",
      "metadata": {
        "id": "281b4792"
      },
      "source": [
        "### 5.5 Long Short Term Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47f7359",
      "metadata": {
        "id": "c47f7359"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d691b647",
      "metadata": {
        "id": "d691b647"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocabulary_size + 1, output_dim = 120, input_length = maxlen))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(20, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d279c246",
      "metadata": {
        "id": "d279c246"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2853c7f4",
      "metadata": {
        "id": "2853c7f4"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_padded, y_train, epochs = 20, validation_data = (X_val_padded, y_val), batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a9a46c",
      "metadata": {
        "id": "55a9a46c"
      },
      "outputs": [],
      "source": [
        "y_predictions = (model.predict(X_test_padded) > 0.5).astype('int32')\n",
        "print(\"F1 Score for RNN: \", f1_score(y_test, y_predictions))\n",
        "test_loss, test_acc = model.evaluate(X_test_padded, y_test)\n",
        "print(\"Test Loss: \", test_loss)\n",
        "print(\"Test Accuracy: \", test_acc)\n",
        "print(classification_report(y_test, y_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4019ef29",
      "metadata": {
        "id": "4019ef29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}